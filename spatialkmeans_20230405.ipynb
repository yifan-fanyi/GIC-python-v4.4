{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c7bc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Framework Version> core.Arithmetic -> 2.5.0\n",
      "<Framework Version> core.Arithmetic -> 2.5.0\n",
      "verbose=True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# @yifan\n",
    "#\n",
    "__version__ = \"2.5.0\"\n",
    "from core.util import myLog\n",
    "import numpy as np\n",
    "import huffman\n",
    "from core.util import *\n",
    "from core.util.evaluate import *\n",
    "from core.util.Arithmetic import *\n",
    "from core.util.myKMeans import *\n",
    "from core.util import Shrink\n",
    "from core.util.Huffman import Huffman\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from core.util.ReSample import resize\n",
    "def readI(ct=1000):\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(ct):\n",
    "        a = cv2.imread('/Users/alex/Desktop/proj/data/train256/'+str(i)+'.png')\n",
    "        x.append(a)\n",
    "        if i < 144:\n",
    "            b = cv2.imread('/Users/alex/Desktop/proj/data/kodak_256/'+str(i)+'.png')\n",
    "            xt.append(b)\n",
    "    return np.array(x).astype('float32'), np.array(xt).astype('float32')\n",
    "    \n",
    "def split(x, xt, win,t=64):\n",
    "    DC = resize(resize(x,t)[:,:,:,:],256).astype('float32')\n",
    "    DCt = resize(resize(xt,t)[:,:,:,:],256).astype('float32')\n",
    "    AC = x[:,:,:,:]-DC\n",
    "    ACt = xt[:,:,:,:]-DCt\n",
    "    if win > 1:\n",
    "        DC, DCt = Shrink(DC, win), Shrink(DCt, win)\n",
    "        AC, ACt = Shrink(AC, win), Shrink(ACt, win)\n",
    "    return DC.astype('float32'), DCt.astype('float32'), AC.astype('float32'), ACt.astype('float32')\n",
    "def entropy(x, nbin):\n",
    "    p = np.zeros((nbin))\n",
    "    x = x.reshape(-1).astype('int32')\n",
    "    for i in range(len(x)):\n",
    "        p[x[i]] +=1.\n",
    "    p = p/np.sum(p)\n",
    "    return -np.sum(p * np.log2(p+1e-10))\n",
    "    \n",
    "def RMSE(x, y):\n",
    "    return np.sqrt(MSE(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232c91fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FRAMEWORK> rdVQ1ac_noT 2023.03.26\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "from core.cwSaab import cwSaab\n",
    "from core.util.myKMeans import myKMeans\n",
    "from core.util.Huffman import Huffman\n",
    "import numpy as np\n",
    "from core.util import Time, myLog, Shrink, invShrink\n",
    "from core.util.ac import HierarchyCABAC, BAC\n",
    "from core.util.evaluate import MSE\n",
    "from core.util.ReSample import *\n",
    "from core.VQEntropy import VQEntropy\n",
    "\n",
    "print('<FRAMEWORK> rdVQ1ac_noT 2023.03.26')\n",
    "\n",
    "def toSpatial(cwSaab, iR, level, S,tX):\n",
    "    for i in range(level, -1, -1):\n",
    "        if i > 0:\n",
    "            iR = cwSaab.inverse_transform_one(iR, tX[i-1], i)\n",
    "        else:\n",
    "            iR = cwSaab.inverse_transform_one(iR, None, i)\n",
    "    return iR\n",
    "def split_km_subspace(KM, dmse, label, win):\n",
    "    def labelfilter(l, nc):\n",
    "        hist = np.zeros(nc)\n",
    "        l = l.reshape(-1)\n",
    "        for i in range(len(l)):\n",
    "            hist[l[i]] +=1\n",
    "        return np.argsort(hist)[::-1]\n",
    "    if win < 8:\n",
    "        idx = dmse > 400\n",
    "    idx = dmse > 200\n",
    "    h = labelfilter(label[idx], len(KM.cluster_centers_))\n",
    "    cent = KM.inverse_predict(h.reshape(-1,1))\n",
    "    km_list = [myKMeans(-1).fit(X=None, cluster_centers=cent[:8]), \n",
    "                myKMeans(-1).fit(X=None, cluster_centers=cent[:16]), \n",
    "               myKMeans(-1).fit(X=None, cluster_centers=cent[:32]),\n",
    "               myKMeans(-1).fit(X=None, cluster_centers=cent[:64]),\n",
    "               myKMeans(-1).fit(X=None, cluster_centers=cent[:128]),\n",
    "               myKMeans(-1).fit(X=None, cluster_centers=cent[:256]),\n",
    "               myKMeans(-1).fit(X=None, cluster_centers=cent[:1024]),\n",
    "               myKMeans(-1).fit(X=None, cluster_centers=cent[:2048]),\n",
    "              ]\n",
    "\n",
    "    return km_list\n",
    "\n",
    "class VQ_noT:\n",
    "    def __init__(self, n_clusters_list, win_list, n_dim_list, enable_skip={}, transform_split=0,Lagrange_multip=300000, acc_bpp=0):\n",
    "        self.n_clusters_list = n_clusters_list\n",
    "        self.win_list = win_list\n",
    "        self.n_dim_list = n_dim_list\n",
    "        self.shape = {}\n",
    "        self.myKMeans = {}\n",
    "        self.Huffman = {}\n",
    "        self.buffer = {}\n",
    "        self.acc_bpp = acc_bpp\n",
    "        self.Lagrange_multip = Lagrange_multip\n",
    "        self.fast=True\n",
    "        self.skip_th_range = {}\n",
    "    def get_myhash(self, level, pos=-1, ispartial=False):\n",
    "        if ispartial == True:\n",
    "            return 'L'+str(level)\n",
    "        return 'L'+str(level)+'-P'+str(pos)\n",
    "    # find the optimal threshold\n",
    "    def RD_search_th(self, myhash, dmse, mse, omse, pidx, label, S, kmidx, isfit):\n",
    "        min_cost, th, lcost = 1e40, -1, 1e40\n",
    "        is0 = False\n",
    "        rx, dx = 0, 0\n",
    "        if isfit == True:\n",
    "            self.skip_th_range[myhash+'_'+str(kmidx)] = np.log2(np.max(dmse)*0.9) / 80\n",
    "        aa = self.skip_th_range[myhash+'_'+str(kmidx)]\n",
    "        e, s = 80, 1\n",
    "        myLog(\"SKIP TH RANGE (%f, %f, %f)\"%(s, e, aa))\n",
    "        if isfit == True:\n",
    "            for k in range(0, (int)(e), (int)(s)):\n",
    "                skip_TH = np.round(np.power(2, aa*float(k))*1000)/1000\n",
    "   \n",
    "                idx = (dmse > skip_TH).reshape(-1)\n",
    "                if np.sum(idx) == 0:\n",
    "                    if is0 == True:\n",
    "                        break\n",
    "                km = self.myKMeans[myhash][kmidx]\n",
    "                nc = km.n_clusters\n",
    "                if k == 0:\n",
    "                    self.Huffman[myhash+'_'+str(kmidx)] = \\\n",
    "                        VQEntropy(nc, km.inverse_predict(np.arange(nc).reshape(-1, 1))).fit(\n",
    "                            label.reshape(S), idx.reshape(S), keep_fit=False, done=False)\n",
    "                elif k == e - s: # last skip_th\n",
    "                    self.Huffman[myhash+'_'+str(kmidx)].fit(\n",
    "                            label.reshape(S), idx.reshape(S), keep_fit=True, done=True)\n",
    "                else:\n",
    "                    self.Huffman[myhash+'_'+str(kmidx)].fit(\n",
    "                            label.reshape(S), idx.reshape(S), keep_fit=True, done=False)\n",
    "        is0 = False         \n",
    "        # encode\n",
    "        for k in range(0, (int)(e), (int)(s)):\n",
    "            if s == 1:\n",
    "                skip_TH = np.round(np.power(2, aa*float(k))*1000)/1000\n",
    "            else:\n",
    "                skip_TH = k\n",
    "            idx = (dmse > skip_TH).reshape(-1)\n",
    "            if np.sum(idx) == 0:\n",
    "                if is0 == True:\n",
    "                    break\n",
    "                else:\n",
    "                    is0 = True\n",
    "            if isfit == True or self.fast==True:\n",
    "                st0=''\n",
    "                l = 2*2.75*min(1-np.sum(idx)/len(idx),np.sum(idx)/len(idx))+0.00276\n",
    "                l = int(l*len(idx))\n",
    "                for i in range(l+1):\n",
    "                    st0+='0'\n",
    "            else:\n",
    "                st0 = HierarchyCABAC().encode(None, idx.reshape(S), 1) \n",
    "            st1 = self.Huffman[myhash+'_'+str(kmidx)].encode(label.reshape(S), idx.reshape(S))\n",
    "            b = self.Huffman[myhash+'_'+str(kmidx)].Huffman.encode(label.reshape(-1)[idx.reshape(-1)])\n",
    "            myLog('condition coding %d, huffman %d'%(len(st1), len(b)))\n",
    "            if len(st1) > len(b):\n",
    "                st1 = b\n",
    "            r = len(st0+st1) / S[0] \n",
    "            d = np.zeros_like(mse)\n",
    "            d[idx.reshape(-1)] += mse[idx.reshape(-1)] \n",
    "            d[idx.reshape(-1)==False] += omse[idx.reshape(-1)==False]\n",
    "            d = np.mean(d)\n",
    "            cost = d + self.Lagrange_multip * r /1024**2 * pow(1.3, 8-int(myhash[1]))\n",
    "            print(skip_TH, r, d, cost)\n",
    "            if min_cost > cost:\n",
    "                min_cost, th, sidx = cost,skip_TH, idx\n",
    "                rx, dx = len(st0+st1), d\n",
    "            if lcost <= cost:\n",
    "                if isfit==False:\n",
    "                    break # early stop if not training \n",
    "            else:\n",
    "                lcost = cost\n",
    "        return th, [min_cost, rx, dx], sidx\n",
    "\n",
    "    # compute the rd cost for given iX\n",
    "    def RD(self, tX, X, iX, label, level, pos, pidx=None, kmidx=-1, isfit=False):\n",
    "        S = [X.shape[0], X.shape[1], X.shape[2], -1]\n",
    "        siX = np.zeros_like(X)\n",
    "        siX += iX\n",
    "        sX = X\n",
    "        sX, siX = sX.reshape(-1, sX.shape[-1]), siX.reshape(-1, siX.shape[-1])\n",
    "        mse = (np.mean(np.square((sX-siX).astype('float32')),axis=1))\n",
    "        omse =  np.mean(np.square(sX.astype('float32')), axis=1)\n",
    "        dmse = omse-mse\n",
    "        th, cost, idx = self.RD_search_th(self.get_myhash(level, pos), dmse, mse, omse, pidx, label, S, kmidx, isfit)\n",
    "        return th, cost, idx\n",
    "\n",
    "    # for each content select suitable codebook\n",
    "    @Time\n",
    "    def RD_search_km(self, tX, X, level, pos, pidx, isfit):\n",
    "        myhash = self.get_myhash(level, pos)\n",
    "        S = [X.shape[0], X.shape[1], X.shape[2], -1]\n",
    "        X = X.reshape(-1, X.shape[-1])\n",
    "        TH, min_cost, skip_idx, tiX, km_idx, lcost = 0, [1e20], None, None, -1, 1e40\n",
    "        for kmidx in range(len(self.myKMeans[myhash])):\n",
    "            iX = np.zeros_like(X).reshape(-1, X.shape[-1])\n",
    "            km = self.myKMeans[myhash][kmidx]\n",
    "            label = km.predict(X[:,:self.n_dim_list[level][pos]]).reshape(-1)\n",
    "            iX[:,:self.n_dim_list[level][pos]] = km.inverse_predict(label.reshape(-1,1))\n",
    "            th, cost, idx = self.RD(tX, X.reshape(S), iX.reshape(S), label, level, pos, pidx, kmidx, isfit)\n",
    "            print('--local-optimal--',cost, th)\n",
    "            if cost[0] < min_cost[0]:\n",
    "                TH, min_cost, skip_idx, tiX = th, cost, idx, iX\n",
    "                km_idx = kmidx\n",
    "            if lcost < cost[0]:\n",
    "                if isfit == False:\n",
    "                    break\n",
    "            else:\n",
    "                lcost = cost[0]\n",
    "        myLog('<INFO> RD_cost=%8.4f r=%f d=%4.5f Skip_TH=%d'%(min_cost[0], min_cost[1], min_cost[2], TH))\n",
    "        tiX = tiX.reshape(-1, tiX.shape[-1])\n",
    "        tiX[skip_idx ==  False] *= 0 \n",
    "        myLog('<BITSTREAM> bpp=%f'%min_cost[1])\n",
    "        self.acc_bpp += min_cost[1] \n",
    "        return tiX.reshape(S)\n",
    "    def get_split(self, km, X, level, pos):\n",
    "        label = tmp[0].predict(X[:,:self.n_dim_list[level][pos]]).reshape(-1)\n",
    "        ix = tmp[0].inverse_predict(label.reshape(-1,1))\n",
    "        sX, siX = X.reshape(-1, X.shape[-1]), ix.reshape(-1, ix.shape[-1])\n",
    "        mse = (np.mean(np.square((sX-siX).astype('float32')),axis=1))\n",
    "        omse =  np.mean(np.square(sX.astype('float32')), axis=1)\n",
    "        dmse = omse-mse\n",
    "        return split_km_subspace(tmp[0], dmse, label, win=self.win_list[level])\n",
    "    @Time\n",
    "    def fit_one_level_one_pos(self, X, tX, level, pos):\n",
    "        myhash = self.get_myhash(level, pos)\n",
    "        self.n_dim_list[level][pos] = min(self.n_dim_list[level][pos], X.shape[-1])\n",
    "        myLog('id=%s vq_dim=%d n_clusters=%d'%(myhash, self.n_dim_list[level][pos], self.n_clusters_list[level][pos]))\n",
    "        S = X.shape\n",
    "        X = X.reshape(-1, X.shape[-1])\n",
    "        nc = self.n_clusters_list[level][pos]\n",
    "        tmp = []\n",
    "        while nc > min(64, self.n_clusters_list[level][pos]//16):\n",
    "            km = myKMeans(nc, KKZinit=True).fit(X[:,:self.n_dim_list[level][pos]])\n",
    "            tmp.append(km)\n",
    "            nc = nc //2\n",
    "       \n",
    "        self.myKMeans[myhash] = tmp + self.get_split(tmp[0], X, level, pos) \\\n",
    "                                    + self.get_split(tmp[1], X, level, pos) \\\n",
    "                                    + self.get_split(tmp[2], X, level, pos) \\\n",
    "                                    + self.get_split(tmp[3], X, level, pos) \n",
    "        X = X.reshape(S)\n",
    "        iX = self.RD_search_km(tX, X, level, pos, self.buffer.get('L'+str(level+1)+'-P'+str(0)+'_idx', None), True)\n",
    "        X[:, :,:,:self.n_dim_list[level][pos]] -= iX[:, :,:,:self.n_dim_list[level][pos]]\n",
    "        return X\n",
    "    \n",
    "    @Time\n",
    "    def fit_one_level(self, iR, tX, level):\n",
    "        myhash = self.get_myhash(level, ispartial=True)\n",
    "        self.shape[myhash] = [iR.shape[0], iR.shape[1], iR.shape[2], -1]\n",
    "        myLog('id=%s'%myhash)\n",
    "        for pos in range(len(self.n_dim_list[level])):\n",
    "            iR = self.fit_one_level_one_pos(iR, tX, level, pos)\n",
    "        return iR.reshape(self.shape[myhash])\n",
    "\n",
    "    @Time\n",
    "    def fit(self, X):\n",
    "        self.isfit=True\n",
    "        X = Shrink(X, self.win_list[0])\n",
    "        iR = self.fit_one_level(X, None, 0)\n",
    "        self.isfit=False\n",
    "        return iR\n",
    "\n",
    "    def predict_one_level_one_pos(self, tX, X, level, pos, skip):\n",
    "        myhash = self.get_myhash(level, pos)\n",
    "        myLog('id=%s'%(myhash))\n",
    "        if myhash in skip:\n",
    "            myLog('<INFO> SKIP CURRENT POS ->%s'%myhash)\n",
    "            return X\n",
    "        self.n_dim_list[level][pos] = min(self.n_dim_list[level][pos], X.shape[-1])\n",
    "        myLog('id=%s vq_dim=%d n_clusters=%d'%(myhash, self.n_dim_list[level][pos], self.n_clusters_list[level][pos]))\n",
    "        S = X.shape\n",
    "        X = X.reshape(-1, X.shape[-1])\n",
    "        X = X.reshape(S)\n",
    "        iX = self.RD_search_km(tX, X, level, pos, self.buffer.get('L'+str(level+1)+'-P'+str(0)+'_idx', None), False)\n",
    "        X[:, :,:,:self.n_dim_list[level][pos]] -= iX[:, :,:,:self.n_dim_list[level][pos]]\n",
    "        return X\n",
    "    \n",
    "    #@Time\n",
    "    def predict_one_level(self, tX, iR, level, skip=[]):\n",
    "        myhash = self.get_myhash(level, ispartial=True)\n",
    "        self.shape[myhash] = [iR.shape[0], iR.shape[1], iR.shape[2], -1]\n",
    "        for pos in range(len(self.n_dim_list[level])):\n",
    "            iR = self.predict_one_level_one_pos(tX, iR, level, pos,skip)\n",
    "        return iR.reshape(self.shape[myhash])\n",
    "\n",
    "    def predict(self, X, skip=[],fast=True):\n",
    "        if X.shape[0]>300:\n",
    "            self.fast=True\n",
    "        else:\n",
    "            self.fast=False\n",
    "        self.buffer = {}\n",
    "        X = Shrink(X, self.win_list[0])\n",
    "        iR = self.predict_one_level([X], X, 0, skip)   \n",
    "        iR = invShrink(X, self.win_list[0])\n",
    "        return iR\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84effa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 256, 256, 3)\n",
      "15.562736 14.710093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1400, 256, 256, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, xt = readI(1400)\n",
    "print(x.shape)\n",
    "DC, DCt, AC, ACt = split(x, xt, 1, t=64)\n",
    "print(np.std(AC), np.std(ACt))\n",
    "AC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cd720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/alex/Desktop/GIC-python-v4.3/tmp_g8_all100000.pkl','rb') as f:\n",
    "# with open('/Users/alex/Desktop/GIC-python-v4.3/tmp_g8_endL3.pkl','rb') as f:\n",
    "    d = pickle.load(f)\n",
    "Xt, iXt = d['x'], d['ix']\n",
    "Xt.shape, iXt.shape\n",
    "r = Xt - iXt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff27141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=L0\n",
      "id=L0-P0 vq_dim=3072 n_clusters=4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 89600 points to 4096 centroids: please provide at least 159744 training points\n"
     ]
    }
   ],
   "source": [
    "nc=4096\n",
    "hhh = 'f'\n",
    "try:\n",
    "    with open('vq32_'+str(nc)+hhh+'.pkl','rb') as f:\n",
    "        vqT = pickle.load(f)#(vqT,f,4)\n",
    "except:\n",
    "    vqT = VQ_noT(n_clusters_list=[[nc]], win_list=[32], n_dim_list=[[30000]],Lagrange_multip=30000, acc_bpp=0)\n",
    "    vqT.fit(AC)\n",
    "    with open('vq32_'+str(nc)+hhh+'.pkl','wb') as f:\n",
    "        pickle.dump(vqT,f,4)\n",
    "    vqT.Lagrange_multip = 3000\n",
    "    AC = vqT.predict(AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdbbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vqT.Lagrange_multip = 1000\n",
    "iR = vqT.predict(r)\n",
    "print('----',MSE(iR, np.zeros_like(iR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d303dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r16 = iR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3811256",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('vq16_'+str(nc)+hhh+'.pkl','rb') as f:\n",
    "        vqT = pickle.load(f)#(vqT,f,4)\n",
    "except:\n",
    "    vqT = VQ_noT(n_clusters_list=[[nc]], win_list=[16], n_dim_list=[[3000]],Lagrange_multip=30000, acc_bpp=0)\n",
    "    vqT.fit(AC)\n",
    "    with open('vq16_'+str(nc)+hhh+'.pkl','wb') as f:\n",
    "        pickle.dump(vqT,f,4)\n",
    "    vqT.Lagrange_multip = 3000\n",
    "    AC = vqT.predict(AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ce88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vqT.Lagrange_multip = 1100\n",
    "iR = vqT.predict(r16)\n",
    "print('----',MSE(r16-iR, r16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a79941",
   "metadata": {},
   "outputs": [],
   "source": [
    "r8 = iR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('vq8_'+str(nc)+hhh+'.pkl','rb') as f:\n",
    "        vqT = pickle.load(f)#(vqT,f,4)\n",
    "except:\n",
    "    vqT = VQ_noT(n_clusters_list=[[nc]], win_list=[8], n_dim_list=[[3000]],Lagrange_multip=30000, acc_bpp=0)\n",
    "    vqT.fit(AC)\n",
    "    with open('vq8_'+str(nc)+hhh+'.pkl','wb') as f:\n",
    "        pickle.dump(vqT,f,4)\n",
    "    vqT.Lagrange_multip = 3000\n",
    "    AC = vqT.predict(AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d4376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vqT.Lagrange_multip = 1200\n",
    "iR = vqT.predict(r8)\n",
    "print('----',MSE(r8-iR, r8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = iR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ebf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('vq4_'+str(nc)+hhh+'.pkl','rb') as f:\n",
    "        vqT = pickle.load(f)#(vqT,f,4)\n",
    "except:\n",
    "    vqT = VQ_noT(n_clusters_list=[[nc]], win_list=[4], n_dim_list=[[3000]],Lagrange_multip=30000, acc_bpp=0)\n",
    "    vqT.fit(AC)\n",
    "    with open('vq4_'+str(nc)+hhh+'.pkl','wb') as f:\n",
    "        pickle.dump(vqT,f,4)\n",
    "    vqT.Lagrange_multip = 3000\n",
    "    AC = vqT.predict(AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e525618",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqT.Lagrange_multip = 1200\n",
    "iR = vqT.predict(r4)\n",
    "print('----', MSE(r4-iR, r4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 = iR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31928980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     with open('vq2_'+str(nc)+hhh+'.pkl','rb') as f:\n",
    "#         vqT = pickle.load(f)#(vqT,f,4)\n",
    "# except:\n",
    "#     vqT = VQ_noT(n_clusters_list=[[nc]], win_list=[4], n_dim_list=[[3000]],Lagrange_multip=30000, acc_bpp=0)\n",
    "#     vqT.fit(AC)\n",
    "#     with open('vq2_'+str(nc)+hhh+'.pkl','wb') as f:\n",
    "#         pickle.dump(vqT,f,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vqT.Lagrange_multip = 1400\n",
    "# iR = vqT.predict(r2)\n",
    "# print('----', MSE(r2-iR, r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637233b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
