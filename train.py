# <IMPORTANT>
# File oraginaztion:
#  all under  `root/`
#   `root/model/` 
#       <dkm_{level}_{win}.model>: pickle file for `class Distributed_KMeans`
#       <vq_{level}_{win}.model>: pickle file for `class VQ_noT`
#   `root/{level}/`
#       <*.data>: * start from 0 end at {n_file-1}
#                 file generated by `write_UCHAR` or `write_SHORT`, use `read` to read them 
#                 save rgb images downsampled to level x level
#                 these files will be generated by `preprocess.ipynb`
#   `root/{level}_RL/`
#       <*.data>: saves the resolution loss between two consecutive level
#                 these files will be generated by `generate_RL` function
#   `root/{level}_{win}/`
#       <*.data>: saves the quantization residual need to perfrom VQ at resolution {level} with block size win x win
#                 notice that `root/{level}_{level+1}/ would save the residual from vq in previous level plus the resolution loss`
# possible {level}={8,16,32,64,128,256}
import numpy as np
from core.rdvq1ac_noT import *
from core.Distributed_KMeans import *
import os
import pickle
from core.util.ReSample import *
FRAME_EACH_FILE=1000
# root: root path
# X: some smaples, will be used to train entropy coding and find the skip_th to derive input for next level
# n_files, residual files, the input will locates in root/{CurrentLevel}_{p_win}/ files are named as 0.data 1.data ...
#   
def gen_file_list(n_file):
    file_list = []
    for i in range(n_file):
        file_list.append(str(i)+'.data')
    return file_list
def train_one_vq(root, X, win, p_win, n_clusters, n_file, Lagrange_multip):
    file_list = gen_file_list(n_file)
    try:
        with open(root+'/model/dkm'+str(X.shape[1])+'_'+str(win)+'.model','rb') as f:
            dkm = pickle.load(f)
    except:
        os.system('mkdir '+root+'/'+str(X.shape[1])+'_'+str(win))
        dkm = Distributed_KMeans(n_clusters=n_clusters, 
                                size=X.shape[1], 
                                win=win, 
                                datatype="SHORT", 
                                frame_each_file=FRAME_EACH_FILE, 
                                n_frames=100).fit(folder=root+'/'+str(X.shape[1])+'_'+str(p_win), 
                                                file_list=file_list)
        with open(root+'/model/dkm_'+str(X.shape[1])+'_'+str(win)+'.model','wb') as f:
            pickle.dump(dkm, f, 4)
    try:
        with open(root+'/model/vq'+str(X.shape[1])+'_'+str(win)+'.model','rb') as f:
            vq = pickle.load(f)
    except:
        vq = VQ_noT(n_clusters_list=[[n_clusters]], win_list=[win], n_dim_list=[[win**2*3]], Lagrange_multip=Lagrange_multip, acc_bpp=0)
        vq.fit(dkm, X)
        with open(root+'/model/vq_'+str(X.shape[1])+'_'+str(win)+'.model','wb') as f:
            pickle.dump(vq, f, 4)

    dkm.predict(root+'/'+str(X.shape[1])+'_'+str(p_win), 
                file_list, 
                root+'/'+str(X.shape[1])+'_'+str(win), 
                th=vq.th*1.1)
    return vq.predict(X)

# distributed KM gives residual
def toNextLevel(root, p_level, p_win, n_level, n_file):
    file_list = gen_file_list(n_file)
    os.system('mkdir '+root+'/'+str(n_level)+'_'+str(n_level+1)+'/'+file)
    for file in file_list:
        file_path = root+'/'+str(p_level)+'_'+str(p_win)+'/'+file
        file_path_RL = root+'/'+str(n_level)+'_RL/'+file
        dst_file = root+'/'+str(n_level)+'_'+str(n_level+1)+'/'+file
        x = read(file_path, "SHORT", p_level, FRAME_EACH_FILE)
        y = read(file_path_RL, "SHORT", n_level, FRAME_EACH_FILE)
        x = ReSample.resize(x, n_level)
        write_SHORT(x+y, dst_file)

def generate_RL(root, level_list, n_file):
    file_list = gen_file_list(n_file)
    for i in range(1, len(level_list)):
        os.system('mkdir '+root+'/'+str(level_list[i])+'_RL/')
    for file in file_list:
        for i in range(1, len(level_list)):
            file_path0 = root+'/'+str(level_list[i-1])+'_/'+file
            file_path1 = root+'/'+str(level_list)+'/'+file
            dst_file = root+'/'+str(level_list[i])+'_RL/'+file
            x = read(file_path0, "SHORT", level_list[i-1], FRAME_EACH_FILE)
            y = read(file_path1, "SHORT", level_list[i], FRAME_EACH_FILE)
            x = ReSample.resize(x, level_list[i])
            write_SHORT(y-x, dst_file)
def first_level(root, level):
    # copy the file to {level}_{level+1} as encode preparation 
    os.system('mkdir '+ root+'/'+str(level)+'_'+str(level+1))
    os.system('cp -r '+root+'/'+str(level)+' '+ root+'/'+str(level)+'_'+str(level+1))
def one_level(root, X, p_level, p_last_win, n_level, win_list, n_clusters_list, n_file, Lagrange_multip_list):
    if p_level is not None:
        toNextLevel(root, p_level, p_last_win, n_level, n_file)
    win_list = [n_level+1]+win_list
    for i in range(1, len(win_list)):
        # X is residual
        X = train_one_vq(root, X, win_list[i], win_list[i-1], n_clusters_list[i-1], n_file, Lagrange_multip_list[i-1])
    return X

def training(X, root, par):
    example_par = {
                    'level_list':[8,16],
                    'n_file':100,
                    8:{
                        'win_list':[],
                        'n_clusters_list':[],
                        'Lagrange_multip_list':[]
                        },
                    16:{
                        'win_list':[],
                        'n_clusters_list':[],
                        'Lagrange_multip_list':[]
                        }
                    }
    first_level(root, par['level_list'][0])
    X = one_level(root, X, p_level=None, p_last_win=None, 
              n_level=par['level_list'][0], 
              win_list=par[par['level_list'][0]]['win_list'], 
              n_clusters_list=par[par['level_list'][0]]['n_clusters_list'], 
              n_file=par['n_file'], 
              Lagrange_multip_list=par[par['level_list'][0]]['Lagrange_multip_list'])
    for i in range(1, len(par['level_list'])):
        X = one_level(root, X, 
                      p_level=par['level_list'][i-1], 
                      p_last_win=par[par['level_list'][i]]['win_list'][-1], 
                      n_level=par['level_list'][i], 
                      win_list=par[par['level_list'][i]]['win_list'], 
                      n_clusters_list=par[par['level_list'][i]]['n_clusters_list'], 
                      n_file=par['n_file'], 
                      Lagrange_multip_list=par[par['level_list'][i]]['Lagrange_multip_list'])
        
if __name__ == "__main__":
    from core.data import *
    t = load('test', 144, size=[256])
    X = t[0]
    print(X.shape)
    train_one_vq(root='/Users/alex/Desktop/test_data/', 
                 X=X, 
                 win=4, 
                 p_win=8, 
                 n_clusters=16, 
                 n_file=2, 
                 Lagrange_multip=1000)
